{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains code used to develop the model.\n",
    "\n",
    "The flow of the code is as follows:\n",
    "1. Setup - load packages\n",
    "2. Ingest the data \n",
    "3. Inspect the data\n",
    "4. Imputation and encoding\n",
    "5. Model selection loop\n",
    "6. Inspect the results\n",
    "7. View the best model\n",
    "8. Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Library Imports\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "#Third Party Library Imports\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, average_precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Local Imports\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global settings\n",
    "n_jobs = -1\n",
    "k_fold = 5 \n",
    "n_repeats = 100\n",
    "n_iter = 500\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "verbose = False\n",
    "return_train_score =  False\n",
    "summary_dict = {}\n",
    "key_dict = {1:'Resolved',0:'Unresolved'}\n",
    "test_size = 0.25\n",
    "drop_first = True\n",
    "missing_indicator = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = pd.read_csv('processed_data/outcome.csv')\n",
    "predictors = pd.read_csv('processed_data/predictors.csv')\n",
    "categorical_features = pd.read_csv('processed_data/categorical_features.csv').values.tolist()\n",
    "categorical_features = [item for sublist in categorical_features for item in sublist]\n",
    "numeric_features = pd.read_csv('processed_data/numeric_features.csv').values.tolist()\n",
    "numeric_features = [item for sublist in numeric_features for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 244\n",
      "\n",
      "Class Breakdown, count:\n",
      "1    156\n",
      "0     88\n",
      "Name: lvtstatus, dtype: int64\n",
      "\n",
      "Class Breakdown, %:\n",
      "1    0.639344\n",
      "0    0.360656\n",
      "Name: lvtstatus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset size: {len(outcome)}')\n",
    "print()\n",
    "print('Class Breakdown, count:')\n",
    "print(outcome['lvtstatus'].value_counts())\n",
    "print()\n",
    "print('Class Breakdown, %:')\n",
    "print(outcome['lvtstatus'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Training Data Predictors (x_train)\n",
    "\n",
    "The x_train matrix is used to get mean and standard deviations used in standardization & scaling, and median imputation of scalar variables. It is also used to get the mode for categorical variables for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,_,_,_ = train_test_split(predictors,outcome,test_size=test_size,random_state=seed,stratify=outcome)\n",
    "train_indices = x_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full List Of Covariates Before Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictors:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Age, years',\n",
       " 'Sex',\n",
       " 'Height, cm',\n",
       " 'Weight, kg',\n",
       " 'Body Mass Index',\n",
       " 'Diabetes Mellitus/Prediabetes',\n",
       " 'Chronic Kidney Disease',\n",
       " 'Venous Thromboembolism',\n",
       " 'Cerebrovascular Accident/Transient Ischemic Attack',\n",
       " 'Heart Failure',\n",
       " 'Post-AMI Atrial Fibrillation',\n",
       " 'Post-AMI Cardiogenic Shock',\n",
       " 'Cardiopulmonary Resuscitation',\n",
       " 'Peak Troponin I, ng/dL',\n",
       " 'Hemoglobin, g/dL',\n",
       " 'White Blood Cell Count, 10^9/L',\n",
       " 'Lymphocyte Count, 10^9/L',\n",
       " 'Neutrophil Count, 10^9/L',\n",
       " 'Platelet Count, 10^9/dL',\n",
       " 'Prothrombin Time, seconds',\n",
       " 'International Normalized Ratio',\n",
       " 'Activated Partial Thromboplastin Time, seconds',\n",
       " 'Creatinine, mmol/L',\n",
       " 'ACS Type',\n",
       " 'Visual Ejection Fraction, %',\n",
       " 'Left Ventricle Internal Diameter At End-diastole, mm',\n",
       " 'Left Ventricle Internal Diameter At End-systole, mm',\n",
       " 'Left Ventricle Outflow Tract, mm',\n",
       " 'Wall Motion Abnormality',\n",
       " 'Left Ventricular Aneurysm',\n",
       " 'LV Thrombus Mobility',\n",
       " 'Protrusion',\n",
       " 'Aspirin Use',\n",
       " 'Second Antiplatelet Agent',\n",
       " 'Coronary Artery Disease',\n",
       " 'Number of Culprit Arteries',\n",
       " 'Revascularization Procedure']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('All predictors:')\n",
    "list(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_encode(df,train_indices,categorical_features=categorical_features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and perform univariate imputation by column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        Dataset to be imputed.\n",
    "    train_indices: array-like\n",
    "        An array of indices for training data - used to fit SimpleImputer obtain\n",
    "    categorical_features: list\n",
    "        An list of strings containing column names for categorical objects. Used to determine type of imputation and whether centering and scaling is necessary\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    imputed_df: pandas.DataFrame\n",
    "        A dataframe containing the imputed and scaled dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    imputed_df = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        if df[column].isna().sum() != 0:\n",
    "            array = df[column].values.reshape(-1, 1)\n",
    "            if column in numeric_features: \n",
    "                si = SimpleImputer(strategy='median',missing_values=np.nan,add_indicator=missing_indicator)\n",
    "                si.fit(array[train_indices])\n",
    "                out = si.transform(array)\n",
    "            else:\n",
    "                si = SimpleImputer(strategy='most_frequent',missing_values=np.nan,add_indicator=missing_indicator)\n",
    "                si.fit(array[train_indices])\n",
    "                out = si.transform(array)\n",
    "            if out.shape[1] == 1:\n",
    "                out = out.flatten()\n",
    "                imputed_df[column] = out\n",
    "            else:\n",
    "                imputed_df[column] = out[:,0]\n",
    "                imputed_df[column+'_missing'] = out[:,1].astype('bool') \n",
    "        else:\n",
    "            imputed_df[column] = df[column]\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column not in categorical_features:\n",
    "            array = imputed_df[column].values.reshape(-1, 1)\n",
    "            std_scaler = StandardScaler()\n",
    "            std_scaler.fit(array[train_indices])\n",
    "            out = std_scaler.transform(array)\n",
    "            out = out.flatten()\n",
    "            imputed_df[column] = out\n",
    "    \n",
    "    for varname in categorical_features:\n",
    "        onehot = pd.get_dummies(imputed_df[varname],prefix=varname,prefix_sep='_',drop_first=drop_first)\n",
    "        imputed_df = imputed_df.drop(varname,axis=1).join(onehot)\n",
    "    return imputed_df\n",
    "predictors = impute_and_encode(predictors,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full List of Covariates After Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age, years</th>\n",
       "      <th>Height, cm</th>\n",
       "      <th>Weight, kg</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Peak Troponin I, ng/dL</th>\n",
       "      <th>Hemoglobin, g/dL</th>\n",
       "      <th>White Blood Cell Count, 10^9/L</th>\n",
       "      <th>Lymphocyte Count, 10^9/L</th>\n",
       "      <th>Neutrophil Count, 10^9/L</th>\n",
       "      <th>Platelet Count, 10^9/dL</th>\n",
       "      <th>...</th>\n",
       "      <th>Protrusion_Yes</th>\n",
       "      <th>Aspirin Use_Yes</th>\n",
       "      <th>Second Antiplatelet Agent_Yes</th>\n",
       "      <th>Coronary Artery Disease_No Vessel Disease</th>\n",
       "      <th>Coronary Artery Disease_Single Vessel Disease</th>\n",
       "      <th>Coronary Artery Disease_Triple Vessel Disease</th>\n",
       "      <th>Number of Culprit Arteries_1.0</th>\n",
       "      <th>Number of Culprit Arteries_2.0</th>\n",
       "      <th>Number of Culprit Arteries_3.0</th>\n",
       "      <th>Revascularization Procedure_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300690</td>\n",
       "      <td>-0.280067</td>\n",
       "      <td>-0.534568</td>\n",
       "      <td>-0.532665</td>\n",
       "      <td>-0.684497</td>\n",
       "      <td>-1.833510</td>\n",
       "      <td>-0.933802</td>\n",
       "      <td>1.924035</td>\n",
       "      <td>-1.768132</td>\n",
       "      <td>-0.475690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221856</td>\n",
       "      <td>1.294908</td>\n",
       "      <td>1.051381</td>\n",
       "      <td>0.462623</td>\n",
       "      <td>-0.552544</td>\n",
       "      <td>0.843878</td>\n",
       "      <td>-0.853208</td>\n",
       "      <td>0.756168</td>\n",
       "      <td>-1.301658</td>\n",
       "      <td>0.077017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.329984</td>\n",
       "      <td>1.426155</td>\n",
       "      <td>1.805673</td>\n",
       "      <td>1.152554</td>\n",
       "      <td>-0.747631</td>\n",
       "      <td>-0.823175</td>\n",
       "      <td>0.652760</td>\n",
       "      <td>0.212974</td>\n",
       "      <td>0.564239</td>\n",
       "      <td>2.123208</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.773695</td>\n",
       "      <td>-0.411315</td>\n",
       "      <td>-1.804617</td>\n",
       "      <td>-1.972613</td>\n",
       "      <td>-0.825860</td>\n",
       "      <td>-1.782993</td>\n",
       "      <td>0.454727</td>\n",
       "      <td>-1.661046</td>\n",
       "      <td>-0.404364</td>\n",
       "      <td>2.323124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.014647</td>\n",
       "      <td>1.557403</td>\n",
       "      <td>0.193937</td>\n",
       "      <td>-0.509024</td>\n",
       "      <td>-0.825584</td>\n",
       "      <td>-0.570591</td>\n",
       "      <td>-1.415067</td>\n",
       "      <td>0.059069</td>\n",
       "      <td>-1.595804</td>\n",
       "      <td>-0.899041</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.960657</td>\n",
       "      <td>0.048053</td>\n",
       "      <td>-1.243732</td>\n",
       "      <td>-0.183215</td>\n",
       "      <td>-0.798155</td>\n",
       "      <td>0.641811</td>\n",
       "      <td>1.983722</td>\n",
       "      <td>-0.149156</td>\n",
       "      <td>-0.019597</td>\n",
       "      <td>-0.969599</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-2.222005</td>\n",
       "      <td>0.376172</td>\n",
       "      <td>0.458262</td>\n",
       "      <td>0.286799</td>\n",
       "      <td>-0.798155</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>-0.058776</td>\n",
       "      <td>-0.149156</td>\n",
       "      <td>-0.019597</td>\n",
       "      <td>1.323547</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-1.591331</td>\n",
       "      <td>0.113676</td>\n",
       "      <td>-0.515227</td>\n",
       "      <td>-0.674917</td>\n",
       "      <td>-0.798155</td>\n",
       "      <td>0.136644</td>\n",
       "      <td>-0.095619</td>\n",
       "      <td>-0.149156</td>\n",
       "      <td>-0.019597</td>\n",
       "      <td>-0.117019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.645320</td>\n",
       "      <td>-1.592546</td>\n",
       "      <td>1.102956</td>\n",
       "      <td>2.248635</td>\n",
       "      <td>-0.798155</td>\n",
       "      <td>0.439744</td>\n",
       "      <td>0.201430</td>\n",
       "      <td>-0.149156</td>\n",
       "      <td>-0.019597</td>\n",
       "      <td>-0.028821</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-0.251149</td>\n",
       "      <td>0.048053</td>\n",
       "      <td>-1.050324</td>\n",
       "      <td>-0.183215</td>\n",
       "      <td>-0.798155</td>\n",
       "      <td>0.591295</td>\n",
       "      <td>1.016586</td>\n",
       "      <td>-0.149156</td>\n",
       "      <td>-0.019597</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age, years  Height, cm  Weight, kg  Body Mass Index  \\\n",
       "0      0.300690   -0.280067   -0.534568        -0.532665   \n",
       "1      0.221856    1.294908    1.051381         0.462623   \n",
       "2     -0.329984    1.426155    1.805673         1.152554   \n",
       "3      0.773695   -0.411315   -1.804617        -1.972613   \n",
       "4     -0.014647    1.557403    0.193937        -0.509024   \n",
       "..          ...         ...         ...              ...   \n",
       "239   -0.960657    0.048053   -1.243732        -0.183215   \n",
       "240   -2.222005    0.376172    0.458262         0.286799   \n",
       "241   -1.591331    0.113676   -0.515227        -0.674917   \n",
       "242   -0.645320   -1.592546    1.102956         2.248635   \n",
       "243   -0.251149    0.048053   -1.050324        -0.183215   \n",
       "\n",
       "     Peak Troponin I, ng/dL  Hemoglobin, g/dL  White Blood Cell Count, 10^9/L  \\\n",
       "0                 -0.684497         -1.833510                       -0.933802   \n",
       "1                 -0.552544          0.843878                       -0.853208   \n",
       "2                 -0.747631         -0.823175                        0.652760   \n",
       "3                 -0.825860         -1.782993                        0.454727   \n",
       "4                 -0.825584         -0.570591                       -1.415067   \n",
       "..                      ...               ...                             ...   \n",
       "239               -0.798155          0.641811                        1.983722   \n",
       "240               -0.798155          0.035610                       -0.058776   \n",
       "241               -0.798155          0.136644                       -0.095619   \n",
       "242               -0.798155          0.439744                        0.201430   \n",
       "243               -0.798155          0.591295                        1.016586   \n",
       "\n",
       "     Lymphocyte Count, 10^9/L  Neutrophil Count, 10^9/L  \\\n",
       "0                    1.924035                 -1.768132   \n",
       "1                    0.756168                 -1.301658   \n",
       "2                    0.212974                  0.564239   \n",
       "3                   -1.661046                 -0.404364   \n",
       "4                    0.059069                 -1.595804   \n",
       "..                        ...                       ...   \n",
       "239                 -0.149156                 -0.019597   \n",
       "240                 -0.149156                 -0.019597   \n",
       "241                 -0.149156                 -0.019597   \n",
       "242                 -0.149156                 -0.019597   \n",
       "243                 -0.149156                 -0.019597   \n",
       "\n",
       "     Platelet Count, 10^9/dL  ...  Protrusion_Yes  Aspirin Use_Yes  \\\n",
       "0                  -0.475690  ...               0                1   \n",
       "1                   0.077017  ...               0                1   \n",
       "2                   2.123208  ...               0                1   \n",
       "3                   2.323124  ...               0                1   \n",
       "4                  -0.899041  ...               0                1   \n",
       "..                       ...  ...             ...              ...   \n",
       "239                -0.969599  ...               0                1   \n",
       "240                 1.323547  ...               0                1   \n",
       "241                -0.117019  ...               0                1   \n",
       "242                -0.028821  ...               0                1   \n",
       "243                 0.018218  ...               0                1   \n",
       "\n",
       "     Second Antiplatelet Agent_Yes  Coronary Artery Disease_No Vessel Disease  \\\n",
       "0                                1                                          0   \n",
       "1                                1                                          0   \n",
       "2                                1                                          0   \n",
       "3                                0                                          0   \n",
       "4                                1                                          0   \n",
       "..                             ...                                        ...   \n",
       "239                              1                                          0   \n",
       "240                              1                                          0   \n",
       "241                              1                                          0   \n",
       "242                              1                                          0   \n",
       "243                              1                                          0   \n",
       "\n",
       "     Coronary Artery Disease_Single Vessel Disease  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                1   \n",
       "..                                             ...   \n",
       "239                                              1   \n",
       "240                                              0   \n",
       "241                                              0   \n",
       "242                                              1   \n",
       "243                                              0   \n",
       "\n",
       "     Coronary Artery Disease_Triple Vessel Disease  \\\n",
       "0                                                1   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                1   \n",
       "4                                                0   \n",
       "..                                             ...   \n",
       "239                                              0   \n",
       "240                                              0   \n",
       "241                                              0   \n",
       "242                                              0   \n",
       "243                                              1   \n",
       "\n",
       "     Number of Culprit Arteries_1.0  Number of Culprit Arteries_2.0  \\\n",
       "0                                 0                               0   \n",
       "1                                 0                               1   \n",
       "2                                 0                               1   \n",
       "3                                 1                               0   \n",
       "4                                 1                               0   \n",
       "..                              ...                             ...   \n",
       "239                               1                               0   \n",
       "240                               0                               1   \n",
       "241                               1                               0   \n",
       "242                               1                               0   \n",
       "243                               1                               0   \n",
       "\n",
       "     Number of Culprit Arteries_3.0  Revascularization Procedure_Yes  \n",
       "0                                 1                                1  \n",
       "1                                 0                                1  \n",
       "2                                 0                                1  \n",
       "3                                 0                                0  \n",
       "4                                 0                                1  \n",
       "..                              ...                              ...  \n",
       "239                               0                                1  \n",
       "240                               0                                1  \n",
       "241                               0                                1  \n",
       "242                               0                                1  \n",
       "243                               0                                0  \n",
       "\n",
       "[244 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age, years',\n",
       " 'Height, cm',\n",
       " 'Weight, kg',\n",
       " 'Body Mass Index',\n",
       " 'Peak Troponin I, ng/dL',\n",
       " 'Hemoglobin, g/dL',\n",
       " 'White Blood Cell Count, 10^9/L',\n",
       " 'Lymphocyte Count, 10^9/L',\n",
       " 'Neutrophil Count, 10^9/L',\n",
       " 'Platelet Count, 10^9/dL',\n",
       " 'Prothrombin Time, seconds',\n",
       " 'International Normalized Ratio',\n",
       " 'Activated Partial Thromboplastin Time, seconds',\n",
       " 'Creatinine, mmol/L',\n",
       " 'Visual Ejection Fraction, %',\n",
       " 'Left Ventricle Internal Diameter At End-diastole, mm',\n",
       " 'Left Ventricle Internal Diameter At End-systole, mm',\n",
       " 'Left Ventricle Outflow Tract, mm',\n",
       " 'Sex_Male',\n",
       " 'Diabetes Mellitus/Prediabetes_Yes',\n",
       " 'Chronic Kidney Disease_Yes',\n",
       " 'Venous Thromboembolism_Yes',\n",
       " 'Cerebrovascular Accident/Transient Ischemic Attack_Yes',\n",
       " 'Heart Failure_Yes',\n",
       " 'Post-AMI Atrial Fibrillation_Yes',\n",
       " 'Post-AMI Cardiogenic Shock_Yes',\n",
       " 'Cardiopulmonary Resuscitation_Yes',\n",
       " 'ACS Type_STEMI',\n",
       " 'Wall Motion Abnormality_Regional',\n",
       " 'Left Ventricular Aneurysm_Yes',\n",
       " 'LV Thrombus Mobility_Yes',\n",
       " 'Protrusion_Yes',\n",
       " 'Aspirin Use_Yes',\n",
       " 'Second Antiplatelet Agent_Yes',\n",
       " 'Coronary Artery Disease_No Vessel Disease',\n",
       " 'Coronary Artery Disease_Single Vessel Disease',\n",
       " 'Coronary Artery Disease_Triple Vessel Disease',\n",
       " 'Number of Culprit Arteries_1.0',\n",
       " 'Number of Culprit Arteries_2.0',\n",
       " 'Number of Culprit Arteries_3.0',\n",
       " 'Revascularization Procedure_Yes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(predictors,outcome,test_size=test_size,random_state=seed,stratify=outcome)\n",
    "y_train = y_train.values.flatten()\n",
    "y_test = y_test.values.flatten()\n",
    "batch_size = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).to_csv('processed_data/x_train.csv')\n",
    "pd.DataFrame(x_test).to_csv('processed_data/x_test.csv')\n",
    "pd.DataFrame(y_train).to_csv('processed_data/y_train.csv')\n",
    "pd.DataFrame(y_test).to_csv('processed_data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 41)\n",
      "(61, 41)\n",
      "(183,)\n",
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "The following cell contain a wrapper function used to perform model selection using a randomised search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(summary_dict,model_lst,param_dict,technique,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,n_iter=n_iter,k_fold=k_fold,n_repeats=n_repeats):\n",
    "    \"\"\"\n",
    "    A wrapper function for the model selection loop\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    summary_dict: dict\n",
    "        An empty dictionary used to store results.\n",
    "    model_lst: list\n",
    "        A list of tuples containing ('model_name',model), models are sklearn estimators\n",
    "    param_dict: dict\n",
    "        A dictionary containing model parameter distributions - to be passed to RandomizedSearchCV\n",
    "    technique: str\n",
    "        A string indicating technique used. Only relevant if testing techniques such as oversampling/SMOTE.\n",
    "    x_train: array-like\n",
    "        An array training set predictors\n",
    "    y_train: array-like\n",
    "        An array containing training set labels\n",
    "    x_test: array-like\n",
    "        An array containing test set predictors\n",
    "    y_test: array-like\n",
    "        An array containing test set labels\n",
    "    n_iter: int\n",
    "        Number of crossvalidation iterations - to be passed to RandomizedSearchCV. Defaults to n_iter parameter at top of script\n",
    "    k_fold: int\n",
    "        Number of crossvalidation folds - to be passed to RandomizedSearchCV. Defaults to k_fold parameter at top of script\n",
    "    n_repeats: int\n",
    "        Number of crossvalidation repeats - to be passed to RandomizedSearchCV. Defaults to n_repeats parameter at top of script\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    summary_dict: pandas.DataFrame\n",
    "        A dataframe containing the best model object and associated crossvalidation results\n",
    "    result_table: pandas.DataFrame\n",
    "        A dataframe containing all model objects and associated crossvalidation results\n",
    "    \"\"\"\n",
    "    iterations = n_iter\n",
    "    \n",
    "    #Full list of scoring metrics, but only roc_auc is used in the end\n",
    "    scoring = {'roc_auc':'roc_auc','average_precision':'average_precision','accuracy': 'accuracy'}\n",
    "    \n",
    "    #Create an empty list used to store the results\n",
    "    result_list = []\n",
    "    \n",
    "    #Loop through the list of models\n",
    "    for name, model in model_lst:\n",
    "\n",
    "        #Define the cross-validation folds\n",
    "        cv = RepeatedStratifiedKFold(n_splits=k_fold,n_repeats=n_repeats)\n",
    "        \n",
    "        #Set AUROC as the optimizing metric\n",
    "        refit_score = 'roc_auc'\n",
    "        \n",
    "        #Set the estimator as the model currently being optimized\n",
    "        estimator = model\n",
    "\n",
    "        #Create the RandomizedSearchCV object\n",
    "        search = RandomizedSearchCV(estimator,param_distributions=param_dict.get(name),random_state=seed,cv=cv,n_iter=iterations,n_jobs=n_jobs,\n",
    "                                      scoring=scoring,refit=refit_score,verbose=verbose,return_train_score=return_train_score)\n",
    "        \n",
    "        #Begin the grid search process\n",
    "        search.fit(x_train, y_train)\n",
    "\n",
    "        #Calculate some metrics on the full training dataset (purely for diagnostics)\n",
    "        y_pred = search.best_estimator_.predict(x_train)\n",
    "        \n",
    "        print('Classification report of best model:')\n",
    "        print(classification_report(y_true=y_train,y_pred=y_pred))\n",
    "        print(f'CV score of best model: {search.best_score_}')\n",
    "        print()\n",
    "    \n",
    "        #Append the results of the best model to results_list\n",
    "        result_list.append((name,search,search.best_score_,search.cv_results_))\n",
    "        \n",
    "        ##End of loop\n",
    "    \n",
    "    #The following code tidies result_list in to a dataframe\n",
    "    result_table = pd.DataFrame(result_list,columns=['name','model','scores','score_dict'])\n",
    "    best_model_index = result_table['scores']==max(result_table['scores'])\n",
    "    model_name = result_table['name'][best_model_index].values.tolist()[0]\n",
    "    best_model = result_table['model'][best_model_index].values.tolist()[0]\n",
    "    summary_dict[technique] = {'Model':model_name}\n",
    "    metrics = ['mean_test_roc_auc','mean_test_average_precision','mean_test_accuracy']\n",
    "    if hasattr(best_model,'best_score_'):\n",
    "        best_score = best_model.best_score_ \n",
    "        for key in [key for key in best_model.cv_results_.keys() if key in metrics]:\n",
    "            summary_dict[technique][key.split('mean_test_')[1]] = best_model.cv_results_[key][best_model.best_index_]\n",
    "        summary_dict[technique]['model obj'] = best_model.best_estimator_\n",
    "    else:\n",
    "        best_score = mean_cv_roc_auc\n",
    "        summary_dict[technique]['model obj'] = best_model\n",
    "        for key in [key for key in best_search.cv_results_.keys() if key in metrics]:\n",
    "            summary_dict[technique][key.split('mean_test_')[1]] = result_table['score_dict'][best_model_index].get(key)\n",
    "    \n",
    "    #Find the overall results\n",
    "    print(f\"Best Cross-Validation score: {best_score}\")        \n",
    "    \n",
    "    return summary_dict, result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell runs the model selection loop \n",
    "\n",
    "#Create model objects\n",
    "logistic = SGDClassifier(loss='log',random_state=seed)\n",
    "gbm = GradientBoostingClassifier(random_state=seed)\n",
    "classifier_list = [('lr',logistic),('gbm',gbm)]\n",
    "\n",
    "#Define the hyperparameter search space\n",
    "params = {'lr':{'alpha':uniform(1e-5,10),\n",
    "                'penalty':['l1', 'l2', 'elasticnet'],\n",
    "                'l1_ratio':uniform(0.01,0.30),\n",
    "                'class_weight':[None,'balanced']},\n",
    "          'gbm':{'loss':['deviance','exponential'],\n",
    "                 'learning_rate':uniform(0.003, 0.3),\n",
    "                 'n_estimators':randint(5, 2000),\n",
    "                 'subsample':uniform(0.5, 0.5),\n",
    "                 'criterion':['friedman_mse','mse','mae'],\n",
    "                 'min_samples_split':randint(2,20),\n",
    "                 'min_samples_leaf':randint(2,20),\n",
    "                 'max_depth':randint(2,10),\n",
    "                 'max_features':['sqrt', 'log2']}}\n",
    "\n",
    "#Run the model selection loop\n",
    "summary_dict, conventional_results = model_selection(summary_dict=summary_dict,model_lst=classifier_list,param_dict=params,technique='conventional')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conventional</th>\n",
       "      <td>gbm</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.71</td>\n",
       "      <td>([DecisionTreeRegressor(ccp_alpha=0.0, criteri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  roc_auc  average_precision  accuracy  \\\n",
       "conventional   gbm     0.75               0.82      0.71   \n",
       "\n",
       "                                                      model obj  \n",
       "conventional  ([DecisionTreeRegressor(ccp_alpha=0.0, criteri...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame.from_dict(summary_dict,orient='index').applymap(lambda cell: np.round(cell,2) if isinstance(cell,float) else cell)\n",
    "summary.to_csv(f'results/train_summary_results.csv')\n",
    "conventional_results.sort_values(by=['scores'],ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyy/anaconda3/envs/lv_thrombus/lib/python3.7/site-packages/sklearn/tree/_classes.py:1233: FutureWarning: the classes_ attribute is to be deprecated from version 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: GradientBoostingClassifier(ccp_alpha=0.0, criterion='mae', init=None,\n",
      "                           learning_rate=0.0101437649430095, loss='exponential',\n",
      "                           max_depth=2, max_features='sqrt',\n",
      "                           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                           min_impurity_split=None, min_samples_leaf=18,\n",
      "                           min_samples_split=17, min_weight_fraction_leaf=0.0,\n",
      "                           n_estimators=282, n_iter_no_change=None,\n",
      "                           presort='deprecated', random_state=2020,\n",
      "                           subsample=0.6753887541590888, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "best_model = summary['model obj'][summary['roc_auc'] == max(summary['roc_auc'])][0]\n",
    "best_technique = summary.index[summary['roc_auc'] == max(summary['roc_auc'])][0]\n",
    "joblib.dump(best_model,f'pickled_objects/{protocol}_best_model.pkl')\n",
    "conventional_modified.to_json('results/train_results.csv')\n",
    "print(f'Best Model: {best_model}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
