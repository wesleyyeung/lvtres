{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Library Imports\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "#Third Party Library Imports\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, average_precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "import xgboost as xgb\n",
    "\n",
    "#Local Imports\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global settings\n",
    "protocol = 'LVTRES'\n",
    "n_jobs = -1\n",
    "k_fold = 5\n",
    "n_repeats = 50\n",
    "n_iter = 200\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "verbose = False\n",
    "return_train_score =  False\n",
    "summary_dict = {}\n",
    "key_dict = {1:'Resolved',0:'Unresolved'}\n",
    "test_size = 0.25\n",
    "drop_first = True\n",
    "missing_indicator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = pd.read_csv('processed_data/outcome.csv')\n",
    "predictors = pd.read_csv('processed_data/predictors.csv')\n",
    "categorical_features = pd.read_csv('processed_data/categorical_features.csv').values.tolist()\n",
    "categorical_features = [item for sublist in categorical_features for item in sublist]\n",
    "numeric_features = pd.read_csv('processed_data/numeric_features.csv').values.tolist()\n",
    "numeric_features = [item for sublist in numeric_features for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 244\n",
      "\n",
      "Class Breakdown, count:\n",
      "1    156\n",
      "0     88\n",
      "Name: lvtstatus, dtype: int64\n",
      "\n",
      "Class Breakdown, %:\n",
      "1    0.639344\n",
      "0    0.360656\n",
      "Name: lvtstatus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset size: {len(outcome)}')\n",
    "print()\n",
    "print('Class Breakdown, count:')\n",
    "print(outcome['lvtstatus'].value_counts())\n",
    "print()\n",
    "print('Class Breakdown, %:')\n",
    "print(outcome['lvtstatus'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,_,_,_ = train_test_split(predictors,outcome,test_size=test_size,random_state=seed,stratify=outcome)\n",
    "train_indices = x_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictors:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Age, years',\n",
       " 'Sex',\n",
       " 'Height, cm',\n",
       " 'Weight, kg',\n",
       " 'Body Mass Index',\n",
       " 'Diabetes Mellitus/Prediabetes',\n",
       " 'Chronic Kidney Disease',\n",
       " 'Venous Thromboembolism',\n",
       " 'Cerebrovascular Accident/Transient Ischemic Attack',\n",
       " 'Heart Failure',\n",
       " 'Post-AMI Atrial Fibrillation',\n",
       " 'Post-AMI Cardiogenic Shock',\n",
       " 'Cardiopulmonary Resuscitation',\n",
       " 'Peak Troponin I, ng/dL',\n",
       " 'Hemoglobin, g/dL',\n",
       " 'White Blood Cell Count, 10^9/L',\n",
       " 'Lymphocyte Count, 10^9/L',\n",
       " 'Neutrophil Count, 10^9/L',\n",
       " 'Platelet Count, 10^9/dL',\n",
       " 'Prothrombin Time, seconds',\n",
       " 'International Normalized Ratio',\n",
       " 'Activated Partial Thromboplastin Time, seconds',\n",
       " 'Creatinine, mmol/L',\n",
       " 'ACS Type',\n",
       " 'Visual Ejection Fraction, %',\n",
       " 'Left Ventricle Internal Diameter At End-diastole, mm',\n",
       " 'Left Ventricle Internal Diameter At End-systole, mm',\n",
       " 'Left Ventricle Outflow Tract, mm',\n",
       " 'Wall Motion Abnormality',\n",
       " 'Left Ventricular Aneurysm',\n",
       " 'LV Thrombus Mobility',\n",
       " 'Protrusion',\n",
       " 'Aspirin Use',\n",
       " 'Second Antiplatelet Agent',\n",
       " 'Coronary Artery Disease',\n",
       " 'Number of Culprit Arteries',\n",
       " 'Revascularization Procedure']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('All predictors:')\n",
    "list(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_encode(df,train_indices,categorical_features=categorical_features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and perform univariate imputation by column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        Dataset to be imputed.\n",
    "    train_indices: array-like\n",
    "        An array of indices for training data - used to fit SimpleImputer obtain\n",
    "    categorical_features: list\n",
    "        An list of strings containing column names for categorical objects. Used to determine type of imputation and whether centering and scaling is necessary\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    imputed_df: pandas.DataFrame\n",
    "        A dataframe containing the imputed and scaled dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    imputed_df = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        if df[column].isna().sum() != 0:\n",
    "            array = df[column].values.reshape(-1, 1)\n",
    "            if column in numeric_features: \n",
    "                si = SimpleImputer(strategy='median',missing_values=np.nan,add_indicator=missing_indicator)\n",
    "                si.fit(array[train_indices])\n",
    "                out = si.transform(array)\n",
    "            else:\n",
    "                si = SimpleImputer(strategy='most_frequent',missing_values=np.nan,add_indicator=missing_indicator)\n",
    "                si.fit(array[train_indices])\n",
    "                out = si.transform(array)\n",
    "            if out.shape[1] == 1:\n",
    "                out = out.flatten()\n",
    "                imputed_df[column] = out\n",
    "            else:\n",
    "                imputed_df[column] = out[:,0]\n",
    "                imputed_df[column+'_missing'] = out[:,1].astype('bool') \n",
    "        else:\n",
    "            imputed_df[column] = df[column]\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column not in categorical_features:\n",
    "            array = imputed_df[column].values.reshape(-1, 1)\n",
    "            std_scaler = StandardScaler()\n",
    "            std_scaler.fit(array[train_indices])\n",
    "            out = std_scaler.transform(array)\n",
    "            out = out.flatten()\n",
    "            imputed_df[column] = out\n",
    "    \n",
    "    for varname in categorical_features:\n",
    "        onehot = pd.get_dummies(imputed_df[varname],prefix=varname,prefix_sep='_',drop_first=drop_first)\n",
    "        imputed_df = imputed_df.drop(varname,axis=1).join(onehot)\n",
    "    return imputed_df\n",
    "predictors = impute_and_encode(predictors,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age, years</th>\n",
       "      <th>Height, cm</th>\n",
       "      <th>Weight, kg</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Peak Troponin I, ng/dL</th>\n",
       "      <th>Hemoglobin, g/dL</th>\n",
       "      <th>White Blood Cell Count, 10^9/L</th>\n",
       "      <th>Lymphocyte Count, 10^9/L</th>\n",
       "      <th>Neutrophil Count, 10^9/L</th>\n",
       "      <th>Platelet Count, 10^9/dL</th>\n",
       "      <th>...</th>\n",
       "      <th>Protrusion_Yes</th>\n",
       "      <th>Aspirin Use_Yes</th>\n",
       "      <th>Second Antiplatelet Agent_Yes</th>\n",
       "      <th>Coronary Artery Disease_No Vessel Disease</th>\n",
       "      <th>Coronary Artery Disease_Single Vessel Disease</th>\n",
       "      <th>Coronary Artery Disease_Triple Vessel Disease</th>\n",
       "      <th>Number of Culprit Arteries_1.0</th>\n",
       "      <th>Number of Culprit Arteries_2.0</th>\n",
       "      <th>Number of Culprit Arteries_3.0</th>\n",
       "      <th>Revascularization Procedure_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.305389</td>\n",
       "      <td>-0.232911</td>\n",
       "      <td>-0.532608</td>\n",
       "      <td>-0.561564</td>\n",
       "      <td>-0.765259</td>\n",
       "      <td>-1.934962</td>\n",
       "      <td>-0.929700</td>\n",
       "      <td>2.032006</td>\n",
       "      <td>-1.786166</td>\n",
       "      <td>-0.380517</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.227117</td>\n",
       "      <td>1.138331</td>\n",
       "      <td>1.132862</td>\n",
       "      <td>0.468128</td>\n",
       "      <td>-0.634885</td>\n",
       "      <td>0.861938</td>\n",
       "      <td>-0.845878</td>\n",
       "      <td>0.823217</td>\n",
       "      <td>-1.335505</td>\n",
       "      <td>0.191755</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.320787</td>\n",
       "      <td>1.252602</td>\n",
       "      <td>1.924976</td>\n",
       "      <td>1.181908</td>\n",
       "      <td>-0.827637</td>\n",
       "      <td>-0.879528</td>\n",
       "      <td>0.720400</td>\n",
       "      <td>0.260990</td>\n",
       "      <td>0.467139</td>\n",
       "      <td>2.310381</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.775021</td>\n",
       "      <td>-0.347182</td>\n",
       "      <td>-1.866338</td>\n",
       "      <td>-2.051287</td>\n",
       "      <td>-0.904930</td>\n",
       "      <td>-1.882190</td>\n",
       "      <td>0.514437</td>\n",
       "      <td>-1.678693</td>\n",
       "      <td>-0.468629</td>\n",
       "      <td>2.517373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007699</td>\n",
       "      <td>1.366872</td>\n",
       "      <td>0.232425</td>\n",
       "      <td>-0.537106</td>\n",
       "      <td>-0.904658</td>\n",
       "      <td>-0.615670</td>\n",
       "      <td>-1.430238</td>\n",
       "      <td>0.101692</td>\n",
       "      <td>-1.619680</td>\n",
       "      <td>-0.818853</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.946963</td>\n",
       "      <td>0.109899</td>\n",
       "      <td>-1.277331</td>\n",
       "      <td>-0.162810</td>\n",
       "      <td>-0.877557</td>\n",
       "      <td>0.650851</td>\n",
       "      <td>2.104663</td>\n",
       "      <td>-0.170051</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>-0.891909</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-2.199314</td>\n",
       "      <td>0.338440</td>\n",
       "      <td>0.510004</td>\n",
       "      <td>0.286225</td>\n",
       "      <td>-0.877557</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>-0.019630</td>\n",
       "      <td>-0.170051</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>1.482412</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-1.573138</td>\n",
       "      <td>0.109899</td>\n",
       "      <td>-0.512297</td>\n",
       "      <td>-0.708734</td>\n",
       "      <td>-0.877557</td>\n",
       "      <td>0.070362</td>\n",
       "      <td>-0.122612</td>\n",
       "      <td>-0.170051</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>-0.124821</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.633875</td>\n",
       "      <td>-1.375614</td>\n",
       "      <td>1.187024</td>\n",
       "      <td>2.315876</td>\n",
       "      <td>-0.877557</td>\n",
       "      <td>0.439764</td>\n",
       "      <td>0.250995</td>\n",
       "      <td>-0.170051</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>0.082171</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-0.242515</td>\n",
       "      <td>0.109899</td>\n",
       "      <td>-1.074224</td>\n",
       "      <td>-0.162810</td>\n",
       "      <td>-0.877557</td>\n",
       "      <td>0.598079</td>\n",
       "      <td>1.098797</td>\n",
       "      <td>-0.170051</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>0.130875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age, years  Height, cm  Weight, kg  Body Mass Index  \\\n",
       "0      0.305389   -0.232911   -0.532608        -0.561564   \n",
       "1      0.227117    1.138331    1.132862         0.468128   \n",
       "2     -0.320787    1.252602    1.924976         1.181908   \n",
       "3      0.775021   -0.347182   -1.866338        -2.051287   \n",
       "4     -0.007699    1.366872    0.232425        -0.537106   \n",
       "..          ...         ...         ...              ...   \n",
       "239   -0.946963    0.109899   -1.277331        -0.162810   \n",
       "240   -2.199314    0.338440    0.510004         0.286225   \n",
       "241   -1.573138    0.109899   -0.512297        -0.708734   \n",
       "242   -0.633875   -1.375614    1.187024         2.315876   \n",
       "243   -0.242515    0.109899   -1.074224        -0.162810   \n",
       "\n",
       "     Peak Troponin I, ng/dL  Hemoglobin, g/dL  White Blood Cell Count, 10^9/L  \\\n",
       "0                 -0.765259         -1.934962                       -0.929700   \n",
       "1                 -0.634885          0.861938                       -0.845878   \n",
       "2                 -0.827637         -0.879528                        0.720400   \n",
       "3                 -0.904930         -1.882190                        0.514437   \n",
       "4                 -0.904658         -0.615670                       -1.430238   \n",
       "..                      ...               ...                             ...   \n",
       "239               -0.877557          0.650851                        2.104663   \n",
       "240               -0.877557          0.017591                       -0.019630   \n",
       "241               -0.877557          0.070362                       -0.122612   \n",
       "242               -0.877557          0.439764                        0.250995   \n",
       "243               -0.877557          0.598079                        1.098797   \n",
       "\n",
       "     Lymphocyte Count, 10^9/L  Neutrophil Count, 10^9/L  \\\n",
       "0                    2.032006                 -1.786166   \n",
       "1                    0.823217                 -1.335505   \n",
       "2                    0.260990                  0.467139   \n",
       "3                   -1.678693                 -0.468629   \n",
       "4                    0.101692                 -1.619680   \n",
       "..                        ...                       ...   \n",
       "239                 -0.170051                 -0.013662   \n",
       "240                 -0.170051                 -0.013662   \n",
       "241                 -0.170051                 -0.013662   \n",
       "242                 -0.170051                 -0.013662   \n",
       "243                 -0.170051                 -0.013662   \n",
       "\n",
       "     Platelet Count, 10^9/dL  ...  Protrusion_Yes  Aspirin Use_Yes  \\\n",
       "0                  -0.380517  ...               0                1   \n",
       "1                   0.191755  ...               0                1   \n",
       "2                   2.310381  ...               0                1   \n",
       "3                   2.517373  ...               0                1   \n",
       "4                  -0.818853  ...               0                1   \n",
       "..                       ...  ...             ...              ...   \n",
       "239                -0.891909  ...               0                1   \n",
       "240                 1.482412  ...               0                1   \n",
       "241                -0.124821  ...               0                1   \n",
       "242                 0.082171  ...               0                1   \n",
       "243                 0.130875  ...               0                1   \n",
       "\n",
       "     Second Antiplatelet Agent_Yes  Coronary Artery Disease_No Vessel Disease  \\\n",
       "0                                1                                          0   \n",
       "1                                1                                          0   \n",
       "2                                1                                          0   \n",
       "3                                0                                          0   \n",
       "4                                1                                          0   \n",
       "..                             ...                                        ...   \n",
       "239                              1                                          0   \n",
       "240                              1                                          0   \n",
       "241                              1                                          0   \n",
       "242                              1                                          0   \n",
       "243                              1                                          0   \n",
       "\n",
       "     Coronary Artery Disease_Single Vessel Disease  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                1   \n",
       "4                                                1   \n",
       "..                                             ...   \n",
       "239                                              1   \n",
       "240                                              0   \n",
       "241                                              0   \n",
       "242                                              1   \n",
       "243                                              1   \n",
       "\n",
       "     Coronary Artery Disease_Triple Vessel Disease  \\\n",
       "0                                                1   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "..                                             ...   \n",
       "239                                              0   \n",
       "240                                              0   \n",
       "241                                              0   \n",
       "242                                              0   \n",
       "243                                              0   \n",
       "\n",
       "     Number of Culprit Arteries_1.0  Number of Culprit Arteries_2.0  \\\n",
       "0                                 0                               0   \n",
       "1                                 0                               1   \n",
       "2                                 0                               1   \n",
       "3                                 1                               0   \n",
       "4                                 1                               0   \n",
       "..                              ...                             ...   \n",
       "239                               1                               0   \n",
       "240                               0                               1   \n",
       "241                               1                               0   \n",
       "242                               1                               0   \n",
       "243                               1                               0   \n",
       "\n",
       "     Number of Culprit Arteries_3.0  Revascularization Procedure_Yes  \n",
       "0                                 1                                1  \n",
       "1                                 0                                1  \n",
       "2                                 0                                1  \n",
       "3                                 0                                0  \n",
       "4                                 0                                1  \n",
       "..                              ...                              ...  \n",
       "239                               0                                1  \n",
       "240                               0                                1  \n",
       "241                               0                                1  \n",
       "242                               0                                1  \n",
       "243                               0                                0  \n",
       "\n",
       "[244 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age, years',\n",
       " 'Height, cm',\n",
       " 'Weight, kg',\n",
       " 'Body Mass Index',\n",
       " 'Peak Troponin I, ng/dL',\n",
       " 'Hemoglobin, g/dL',\n",
       " 'White Blood Cell Count, 10^9/L',\n",
       " 'Lymphocyte Count, 10^9/L',\n",
       " 'Neutrophil Count, 10^9/L',\n",
       " 'Platelet Count, 10^9/dL',\n",
       " 'Prothrombin Time, seconds',\n",
       " 'International Normalized Ratio',\n",
       " 'Activated Partial Thromboplastin Time, seconds',\n",
       " 'Creatinine, mmol/L',\n",
       " 'Visual Ejection Fraction, %',\n",
       " 'Left Ventricle Internal Diameter At End-diastole, mm',\n",
       " 'Left Ventricle Internal Diameter At End-systole, mm',\n",
       " 'Left Ventricle Outflow Tract, mm',\n",
       " 'Sex_Male',\n",
       " 'Diabetes Mellitus/Prediabetes_Yes',\n",
       " 'Chronic Kidney Disease_Yes',\n",
       " 'Venous Thromboembolism_Yes',\n",
       " 'Cerebrovascular Accident/Transient Ischemic Attack_Yes',\n",
       " 'Heart Failure_Yes',\n",
       " 'Post-AMI Atrial Fibrillation_Yes',\n",
       " 'Post-AMI Cardiogenic Shock_Yes',\n",
       " 'Cardiopulmonary Resuscitation_Yes',\n",
       " 'ACS Type_STEMI',\n",
       " 'Wall Motion Abnormality_Regional',\n",
       " 'Left Ventricular Aneurysm_Yes',\n",
       " 'LV Thrombus Mobility_Yes',\n",
       " 'Protrusion_Yes',\n",
       " 'Aspirin Use_Yes',\n",
       " 'Second Antiplatelet Agent_Yes',\n",
       " 'Coronary Artery Disease_No Vessel Disease',\n",
       " 'Coronary Artery Disease_Single Vessel Disease',\n",
       " 'Coronary Artery Disease_Triple Vessel Disease',\n",
       " 'Number of Culprit Arteries_1.0',\n",
       " 'Number of Culprit Arteries_2.0',\n",
       " 'Number of Culprit Arteries_3.0',\n",
       " 'Revascularization Procedure_Yes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(predictors,outcome,test_size=test_size,random_state=seed,stratify=outcome)\n",
    "y_train = y_train.values.flatten()\n",
    "y_test = y_test.values.flatten()\n",
    "batch_size = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).to_csv('processed_data/x_train.csv')\n",
    "pd.DataFrame(x_test).to_csv('processed_data/x_test.csv')\n",
    "pd.DataFrame(y_train).to_csv('processed_data/y_train.csv')\n",
    "pd.DataFrame(y_test).to_csv('processed_data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 41)\n",
      "(61, 41)\n",
      "(183,)\n",
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(summary_dict,model_lst,param_dict,technique,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,n_iter=n_iter,k_fold=k_fold,n_repeats=n_repeats):\n",
    "    \"\"\"\n",
    "    A wrapper function for the model selection loop\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    summary_dict: dict\n",
    "        An empty dictionary used to store results.\n",
    "    model_lst: list\n",
    "        A list of tuples containing ('model_name',model), models are sklearn estimators\n",
    "    param_dict: dict\n",
    "        A dictionary containing model parameter distributions - to be passed to RandomizedSearchCV\n",
    "    technique: str\n",
    "        A string indicating technique used. Only relevant if testing techniques such as oversampling/SMOTE.\n",
    "    x_train: array-like\n",
    "        An array training set predictors\n",
    "    y_train: array-like\n",
    "        An array containing training set labels\n",
    "    x_test: array-like\n",
    "        An array containing test set predictors\n",
    "    y_test: array-like\n",
    "        An array containing test set labels\n",
    "    n_iter: int\n",
    "        Number of crossvalidation iterations - to be passed to RandomizedSearchCV. Defaults to n_iter parameter at top of script\n",
    "    k_fold: int\n",
    "        Number of crossvalidation folds - to be passed to RandomizedSearchCV. Defaults to k_fold parameter at top of script\n",
    "    n_repeats: int\n",
    "        Number of crossvalidation repeats - to be passed to RandomizedSearchCV. Defaults to n_repeats parameter at top of script\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    summary_dict: pandas.DataFrame\n",
    "        A dataframe containing the best model object and associated crossvalidation results\n",
    "    result_table: pandas.DataFrame\n",
    "        A dataframe containing all model objects and associated crossvalidation results\n",
    "    \"\"\"\n",
    "    iterations = n_iter\n",
    "    scoring = {'roc_auc':'roc_auc','average_precision':'average_precision','accuracy': 'accuracy','f1':'f1'}\n",
    "    \n",
    "    result_list = []\n",
    "    for name, model in model_lst:\n",
    "\n",
    "        cv = RepeatedStratifiedKFold(n_splits=k_fold,n_repeats=n_repeats)\n",
    "        refit_score = 'roc_auc'\n",
    "        \n",
    "        estimator = model\n",
    "        if name =='DNN':\n",
    "            n_jobs = 1\n",
    "            x_train = x_train.to_numpy().astype('float64')\n",
    "            if iterations > 10:\n",
    "                iterations = np.amin([iterations,100])\n",
    "        elif name == 'lgb':\n",
    "            x_train.columns = [re.sub(r'\\W+', '', colname) for colname in x_train.columns]\n",
    "        else:\n",
    "            n_jobs = -1\n",
    "\n",
    "        search = RandomizedSearchCV(estimator,param_distributions=param_dict.get(name),random_state=seed,cv=cv,n_iter=iterations,n_jobs=n_jobs,\n",
    "                                      scoring=scoring,refit=refit_score,verbose=verbose,return_train_score=return_train_score)\n",
    "        search.fit(x_train, y_train)\n",
    "\n",
    "        print(f'Model: {name}')\n",
    "        if search.best_score_ == 0:\n",
    "            print('No candidate models met minimum requirements')\n",
    "        else:\n",
    "            y_pred = search.best_estimator_.predict(x_train)\n",
    "            if name == 'DNN':\n",
    "                y_pred = y_pred > 0.5\n",
    "\n",
    "            print('Classification report of best model:')\n",
    "            print(classification_report(y_true=y_train,y_pred=y_pred))\n",
    "            print(f'CV score of best model: {search.best_score_}')\n",
    "\n",
    "        result_list.append((name,search,search.best_score_,search.cv_results_))\n",
    "        print()\n",
    "    \n",
    "    print(f'Model: Ensemble')\n",
    "    unpacked_results = [(r[0],r[1].best_estimator_) for r in result_list if r[0] not in ['svm','DNN']]\n",
    "    ensemble = VotingClassifier(unpacked_results,voting='soft')\n",
    "    cross_v = cross_validate(ensemble,x_train,y_train,cv=cv,n_jobs=n_jobs,scoring=scoring)\n",
    "    ensemble.fit(x_train,y_train)\n",
    "    y_pred = ensemble.predict(x_train)\n",
    "    print(classification_report(y_true=y_train,y_pred=y_pred))\n",
    "    score_dict = {}\n",
    "    for i in range(k_fold*n_repeats):\n",
    "        score_dict[f'split{i}_test_roc_auc'] = cross_v['test_roc_auc']\n",
    "        score_dict[f'split{i}_test_average_precision'] = cross_v['test_average_precision']\n",
    "        score_dict[f'split{i}_test_accuracy'] = cross_v['test_accuracy']\n",
    "        score_dict[f'split{i}_test_f1_score'] = cross_v['test_f1']\n",
    "    mean_cv_roc_auc = np.mean(cross_v['test_roc_auc'])\n",
    "    print(f'Cross-Validation Score:{mean_cv_roc_auc}')\n",
    "    result_list.append(('Ensemble',ensemble,mean_cv_roc_auc,score_dict))\n",
    "    print()\n",
    "    \n",
    "    result_table = pd.DataFrame(result_list,columns=['name','model','scores','score_dict'])\n",
    "    \n",
    "    best_model_index = result_table['scores']==max(result_table['scores'])\n",
    "    model_name = result_table['name'][best_model_index].values.tolist()[0]\n",
    "    best_model = result_table['model'][best_model_index].values.tolist()[0]\n",
    "    \n",
    "    summary_dict[technique] = {'Model':model_name}\n",
    "    \n",
    "    metrics = ['mean_test_roc_auc','mean_test_average_precision','mean_test_accuracy','mean_test_f1_score']\n",
    "    \n",
    "    if hasattr(best_model,'best_score_'):\n",
    "        best_score = best_model.best_score_ \n",
    "        for key in [key for key in best_model.cv_results_.keys() if key in metrics]:\n",
    "            summary_dict[technique][key.split('mean_test_')[1]] = best_model.cv_results_[key][best_model.best_index_]\n",
    "        summary_dict[technique]['model obj'] = best_model.best_estimator_\n",
    "    else:\n",
    "        best_score = mean_cv_roc_auc\n",
    "        summary_dict[technique]['model obj'] = best_model\n",
    "        for key in [key for key in best_search.cv_results_.keys() if key in metrics]:\n",
    "            summary_dict[technique][key.split('mean_test_')[1]] = result_table['score_dict'][best_model_index].get(key)\n",
    "        \n",
    "    print(f\"Best Cross-Validation score: {best_score}\")        \n",
    "    \n",
    "    return summary_dict, result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lr\n",
      "Classification report of best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        66\n",
      "           1       0.64      1.00      0.78       117\n",
      "\n",
      "    accuracy                           0.64       183\n",
      "   macro avg       0.32      0.50      0.39       183\n",
      "weighted avg       0.41      0.64      0.50       183\n",
      "\n",
      "CV score of best model: 0.6928318903318904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyy/anaconda3/envs/lv_thrombus/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: svm\n",
      "Classification report of best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        66\n",
      "           1       0.64      1.00      0.78       117\n",
      "\n",
      "    accuracy                           0.64       183\n",
      "   macro avg       0.32      0.50      0.39       183\n",
      "weighted avg       0.41      0.64      0.50       183\n",
      "\n",
      "CV score of best model: 0.6889310966810968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyy/anaconda3/envs/lv_thrombus/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: rf\n",
      "Classification report of best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.30      0.46        66\n",
      "           1       0.72      0.99      0.83       117\n",
      "\n",
      "    accuracy                           0.74       183\n",
      "   macro avg       0.83      0.65      0.65       183\n",
      "weighted avg       0.80      0.74      0.70       183\n",
      "\n",
      "CV score of best model: 0.7037914862914864\n",
      "\n",
      "Model: gbm\n",
      "Classification report of best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.59      0.68        66\n",
      "           1       0.80      0.92      0.86       117\n",
      "\n",
      "    accuracy                           0.80       183\n",
      "   macro avg       0.81      0.76      0.77       183\n",
      "weighted avg       0.80      0.80      0.79       183\n",
      "\n",
      "CV score of best model: 0.6963697691197692\n",
      "\n",
      "Model: xgb\n",
      "Classification report of best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.65      0.75        66\n",
      "           1       0.83      0.96      0.89       117\n",
      "\n",
      "    accuracy                           0.85       183\n",
      "   macro avg       0.86      0.80      0.82       183\n",
      "weighted avg       0.85      0.85      0.84       183\n",
      "\n",
      "CV score of best model: 0.6671302308802308\n",
      "\n",
      "Model: lgb\n",
      "Classification report of best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        66\n",
      "           1       1.00      1.00      1.00       117\n",
      "\n",
      "    accuracy                           1.00       183\n",
      "   macro avg       1.00      1.00      1.00       183\n",
      "weighted avg       1.00      1.00      1.00       183\n",
      "\n",
      "CV score of best model: 0.6371435786435786\n",
      "\n",
      "Model: Ensemble\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        66\n",
      "           1       0.91      1.00      0.95       117\n",
      "\n",
      "    accuracy                           0.93       183\n",
      "   macro avg       0.95      0.91      0.93       183\n",
      "weighted avg       0.94      0.93      0.93       183\n",
      "\n",
      "Cross-Validation Score:0.6784152236652237\n",
      "\n",
      "Best Cross-Validation score: 0.7037914862914864\n"
     ]
    }
   ],
   "source": [
    "logistic = SGDClassifier(loss='log',random_state=seed)\n",
    "svm = SGDClassifier(loss='hinge',random_state=seed)\n",
    "gbm = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "classifier_list = [('lr',logistic),('svm',svm),('gbm',gbm)]\n",
    "params = {'lr':{'alpha':uniform(1e-5,10),\n",
    "                'penalty':['l1', 'l2', 'elasticnet'],\n",
    "                'l1_ratio':uniform(0.01,0.30),\n",
    "                'class_weight':[None,'balanced']},\n",
    "          'svm':{'alpha':uniform(1e-5,10),\n",
    "                 'class_weight':[None,'balanced']},\n",
    "          'rf':{'bootstrap':[True,False],\n",
    "                'criterion':['gini','entropy'],\n",
    "                'max_depth':randint(2,10),\n",
    "                'max_features':['sqrt', 'log2'],\n",
    "                'min_samples_leaf':randint(2,20),\n",
    "                'min_samples_split':randint(2,20),\n",
    "                'n_estimators':randint(5, 2000),\n",
    "                'class_weight':[None,'balanced']},\n",
    "          'gbm':{'loss':['deviance','exponential'],\n",
    "                 'learning_rate':uniform(0.003, 0.3),\n",
    "                 'n_estimators':randint(5, 2000),\n",
    "                 'subsample':uniform(0.5, 0.5),\n",
    "                 'criterion':['friedman_mse','mse','mae'],\n",
    "                 'min_samples_split':randint(2,20),\n",
    "                 'min_samples_leaf':randint(2,20),\n",
    "                 'max_depth':randint(2,10),\n",
    "                 'max_features':['sqrt', 'log2']}}\n",
    "\n",
    "summary_dict, conventional_results = model_selection(summary_dict=summary_dict,model_lst=classifier_list,param_dict=params,technique='conventional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conventional</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>(DecisionTreeClassifier(ccp_alpha=0.0, class_w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  roc_auc  average_precision  accuracy  \\\n",
       "conventional    rf      0.7               0.81      0.66   \n",
       "\n",
       "                                                      model obj  \n",
       "conventional  (DecisionTreeClassifier(ccp_alpha=0.0, class_w...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame.from_dict(summary_dict,orient='index').applymap(lambda cell: np.round(cell,2) if isinstance(cell,float) else cell)\n",
    "summary.to_csv(f'results.csv')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loop extracts the 95% confidence intervals for performance metrics obtained during repeated k-fold crossvalidation\n",
    "confidence_intervals = []\n",
    "for index in range(len(conventional_results)):\n",
    "    cv_dict = {}\n",
    "    name = conventional_results['name']\n",
    "    roc_list = []\n",
    "    for i in range(k_fold*n_repeats):\n",
    "        roc_list.append(conventional_results['score_dict'][index].get(f'split{i}_test_roc_auc'))\n",
    "    array = np.array(roc_list)\n",
    "    array = array.flatten()\n",
    "    lowerbound = np.quantile(array,0.025)\n",
    "    upperbound = np.quantile(array,0.975)\n",
    "    confidence_intervals.append((lowerbound,upperbound))\n",
    "confidence_intervals = pd.DataFrame(confidence_intervals,columns=['0.025%','0.975%'])\n",
    "conventional_results = conventional_results.join(confidence_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>scores</th>\n",
       "      <th>score_dict</th>\n",
       "      <th>0.025%</th>\n",
       "      <th>0.975%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>RandomizedSearchCV(cv=RepeatedStratifiedKFold(...</td>\n",
       "      <td>0.703791</td>\n",
       "      <td>{'mean_fit_time': [2.278679951667786, 0.662842...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbm</td>\n",
       "      <td>RandomizedSearchCV(cv=RepeatedStratifiedKFold(...</td>\n",
       "      <td>0.696370</td>\n",
       "      <td>{'mean_fit_time': [0.5662438645362854, 0.35783...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.896104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>RandomizedSearchCV(cv=RepeatedStratifiedKFold(...</td>\n",
       "      <td>0.692832</td>\n",
       "      <td>{'mean_fit_time': [0.003051578998565674, 0.003...</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.870130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm</td>\n",
       "      <td>RandomizedSearchCV(cv=RepeatedStratifiedKFold(...</td>\n",
       "      <td>0.688931</td>\n",
       "      <td>{'mean_fit_time': [0.0029326467514038087, 0.00...</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.896104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>VotingClassifier(estimators=[('lr',\\n         ...</td>\n",
       "      <td>0.678415</td>\n",
       "      <td>{'split0_test_roc_auc': [0.8928571428571428, 0...</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>RandomizedSearchCV(cv=RepeatedStratifiedKFold(...</td>\n",
       "      <td>0.667130</td>\n",
       "      <td>{'mean_fit_time': [0.2494613356590271, 0.25274...</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb</td>\n",
       "      <td>RandomizedSearchCV(cv=RepeatedStratifiedKFold(...</td>\n",
       "      <td>0.637144</td>\n",
       "      <td>{'mean_fit_time': [0.024657958984375, 0.033246...</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                              model    scores  \\\n",
       "0        rf  RandomizedSearchCV(cv=RepeatedStratifiedKFold(...  0.703791   \n",
       "1       gbm  RandomizedSearchCV(cv=RepeatedStratifiedKFold(...  0.696370   \n",
       "2        lr  RandomizedSearchCV(cv=RepeatedStratifiedKFold(...  0.692832   \n",
       "3       svm  RandomizedSearchCV(cv=RepeatedStratifiedKFold(...  0.688931   \n",
       "4  Ensemble  VotingClassifier(estimators=[('lr',\\n         ...  0.678415   \n",
       "5       xgb  RandomizedSearchCV(cv=RepeatedStratifiedKFold(...  0.667130   \n",
       "6       lgb  RandomizedSearchCV(cv=RepeatedStratifiedKFold(...  0.637144   \n",
       "\n",
       "                                          score_dict    0.025%    0.975%  \n",
       "0  {'mean_fit_time': [2.278679951667786, 0.662842...  0.428571  0.916667  \n",
       "1  {'mean_fit_time': [0.5662438645362854, 0.35783...  0.375000  0.896104  \n",
       "2  {'mean_fit_time': [0.003051578998565674, 0.003...  0.480519  0.870130  \n",
       "3  {'mean_fit_time': [0.0029326467514038087, 0.00...  0.441558  0.896104  \n",
       "4  {'split0_test_roc_auc': [0.8928571428571428, 0...  0.430556  0.904762  \n",
       "5  {'mean_fit_time': [0.2494613356590271, 0.25274...  0.369048  0.861111  \n",
       "6  {'mean_fit_time': [0.024657958984375, 0.033246...  0.389610  0.805195  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conventional_results.sort_values(by=['scores'],ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=2, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=12, min_samples_split=10,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=114,\n",
      "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
      "                       warm_start=False)\n",
      "\n",
      "Classification report on test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.41      0.55        22\n",
      "           1       0.74      0.95      0.83        39\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.78      0.68      0.69        61\n",
      "weighted avg       0.77      0.75      0.73        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = summary['model obj'][summary['roc_auc'] == max(summary['roc_auc'])][0]\n",
    "best_technique = summary.index[summary['roc_auc'] == max(summary['roc_auc'])][0]\n",
    "joblib.dump(best_model,f'pickled_objects/{protocol}_best_model.pkl')\n",
    "conventional_results.to_csv('train_results.csv',index=False)\n",
    "print(f'Best Model: {best_model}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
